For the sentence segmentation we used the spacy library, also the collections library for the counting and matplotlib for the figures . Each category is displayed in figure 1. The x-axis is shows the length of a review in number of sentences, and the y-axis shows the total number of reviews of such length.\\
\begin{Verbatim}
def __init__(self, reviews : list) -> ():
	...
	self.nlp = en_core_web_sm.load()
...
# Sentence Segmentation
ret_dict = collections.defaultdict(int)
	for elem in text:
		doc = self.nlp(elem['text'])
		length = len(list(doc.sents))
		ret_dict[length] = ret_dict[length] + 1
\end{Verbatim}
	\begin{center}
		\begin{table}[!h]
			\caption{Average length of the sentences in the different star categories}
			\begin{tabular}{c | c | c | c | c}
				1 Star & 2 Star & 3 Star  & 4 Star & 5 Star\\\hline
				30.5 & 25.9 & 24.0  & 25 & 24\\
			\end{tabular}
		\end{table}
	\end{center}
	
As can be seen, the length of the reviews are larger in bad ratings than in good ratings. This can also be seen in the average review length (Table 1). The average length of a review with a 1 star rating is 6 sentences larger than the average length of sentences of a review with 5 Stars. 
	